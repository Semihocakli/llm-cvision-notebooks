{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yeni başlayanlar için Çekiştirmeli Üretici Ağlar (ÇÜAlar) veya Generative Adversarial Networks (GANs) \n",
    "## Cifar 10 kullanarak renkli küçük resimler oluşturmak için GAN\n",
    "###  [Meltem Atay](https://github.com/neuroscitechie) tarafından Deep Learning Türkiye  Ankara Toplantısı için Türkçeleştirildi.\n",
    "\n",
    "<img src=\"notebook-images/dltr.png\" />\n",
    "Kaynak kitap: [the O'Reilly interactive tutorial on generative adversarial networks](https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners). \n",
    "\n",
    "### Kullanılan kütüphaneler:\n",
    "\n",
    " [TensorFlow](https://www.tensorflow.org/install/), \n",
    " [NumPy](https://docs.scipy.org/doc/numpy/user/install.html), \n",
    " [matplotlib](https://matplotlib.org/) \n",
    " [Jupyter](https://jupyter.readthedocs.io/en/latest/install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giriş\n",
    "\n",
    "Yann Lecun'a göre çekişmeli öğrenme derin öğrenmenin en iyi fikirlerindendir. \n",
    "<img src=\"notebook-images/lecun.jpeg\" />\n",
    "GAN'lar ilk olarak [Ian Goodfellow et al. in 2014](https://arxiv.org/abs/1406.2661) tarafından tarif edildiğinden beri büyük ilgi oldağı olmuştur.\n",
    "GAN'lar girdi olarak verilen verisetinden sentetik veri seti oluşturmaya yönelik çalışan yapay sinir ağlarıdır.\n",
    "Örnek GAN çalışmaları:\n",
    "<img src=\"notebook-images/lsun_bedrooms_real.png\" />\n",
    "\n",
    "<img src=\"notebook-images/lsun_bedrooms_five_epoch_samples.png\" />\n",
    "\n",
    "<img src=\"notebook-images/albums_128px.png\" />\n",
    "\n",
    "<img src=\"notebook-images/faces_arithmetic_collage_v2.png\" />\n",
    "\n",
    "<img src=\"notebook-images/faces_128_filter_samples.png\" />\n",
    "\n",
    "<img src=\"notebook-images/faces_arithmetic_collage_v2.png\" />\n",
    "\n",
    "\n",
    "Bu çalışmalar oldukça karmaşık olsa da, aslında GAN oluşturmak o kadar da zor değildir...\n",
    "Örneğin MNIST üzerinden vanilla-GAN kullanılarak oluşan sentetik rakamlar aşağıdadır.\n",
    "\n",
    "\n",
    "<img src=\"notebook-images/gan-animation.gif\" />\n",
    "Çalışma boyunca en stabil GAN mimarilerinden olan WGAN kullanarak CIFAR10 veri setinde yeni objeler oluşturacağız. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Mimarisi\n",
    "### Örnek olarak DCGAN (derin evrişimsel üretici ağ yapısı)\n",
    "\n",
    "GAN yapısı iki modelin bir araya gelmesinden oluşur: \n",
    "Üretici model ve Ayırt edici model:\n",
    "![caption](notebook-images/GAN_Overall.png)\n",
    "Ayırt edici model elindeki resmin gerçek verisetindeki resimlere veya uydurma bir olabileceğini sınıflayan basit bir ikili sınıflandırma yapısıdır. Bilinen bir evrişimsel sinir ağı yapısında olabilir.\n",
    "\n",
    "Üretici Model ise veri seti içinden rastgele girdi değerlerini alıp bunları yeni resimlere dönüştürür. Üretici ağ genelde evrişim işleminin tersini alarak çalışmaktadır ancak güncel mimarilerde bu da değişmektedir.\n",
    "\n",
    "Üretici ve Ayırt Edici ağlarının ağırlık ve biasları backpropagation (geri besleme) algoritması ile birlikte hesaplanır.\n",
    "Ayırt edici ağ, üretilen resimleri gerçek veya uydurma olarak ayırmaya çalışırken, üretici ağ ise ayırt edici ağı kandıracak resimleri ayırt edici ağı daha iyi kandıracak şekilde üretmeye çalışır.\n",
    "![caption](notebook-images/ganm.png)\n",
    "![caption](notebook-images/GAN Algorithm.png)\n",
    "\n",
    "![caption](notebook-images/ganthing.png)\n",
    "- Mavi çizgi Ayırt edici Ağ için loss fonksiyonu grafiği\n",
    "- Siyah Nokta veri seti miktarı\n",
    "- Yeşil çizgi üretilen veri seti miktarı\n",
    "\n",
    "\n",
    "a) training başı\n",
    "b) yeni resimler üretilmeye başladıkça\n",
    "c) daha çok resim üretildiğindeki durum\n",
    "d) girdi veriseti ile üretilen veriseti aynı boyutlara ulaştığındaki son durum ~ Nash-Equilibrium..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadi başlayalım...\n",
    "\n",
    "Bu uygulamada [Keras](https://keras.io/)  ve  [TensorFlow](https://www.tensorflow.org/), kullanağız.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri seti:\n",
    "### cifar 10 \n",
    "<img src=\"notebook-images/cifar10.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kod  https://github.com/martinarjovsky/WassersteinGAN kaynağından uyarlanmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keras arkasında tensorflow backend kullanıyoruz\n",
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow' \n",
    "os.environ['THEANO_FLAGS']='floatX=float32,device=cuda,optimizer=fast_compile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ayırt edici ağ\n",
    "\n",
    "WassersteinGAN-DCGAN'ın üzerinde farklı bir kayıp (loss) fonksiyonu kullanarak çalıştığı için ayırt edici ağ bir evrişimsel sinir ağıdır, cifar 10'un resim boyutu 32x32 olduğu için girdi olarak 32x32x3 kanallı resim girdisini alır, ve bunu veri seti içinde bulunan  \"gerçek\" veya üretici ağ tarafından oluşturulmuş \"uydurma\" olarak ikili sınıflamalardan birini temsil eden bir skalar değere dönüştürür.\n",
    "\n",
    "![caption](notebook-images/GAN_D.png)\n",
    "Ayırt edici ağ yapısı [TensorFlow'un CNN modeli](https://www.tensorflow.org/get_started/mnist/pros) gibi olsa da 3 evrişimsel sinir ağı ve 4x4 filtreden oluşmaktadır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCGAN_D(isize, nz, nc, ndf, n_extra_layers=0):\n",
    "    assert isize%2==0\n",
    "    _ = inputs = Input(shape=(nc, isize, isize))\n",
    "    _ = Conv2D(filters=ndf, kernel_size=4, strides=2, use_bias=False,\n",
    "                        padding = \"same\",\n",
    "                        kernel_initializer = conv_init, \n",
    "                        name = 'initial.conv.{0}-{1}'.format(nc, ndf)             \n",
    "                        ) (_)\n",
    "    _ = LeakyReLU(alpha=0.2, name = 'initial.relu.{0}'.format(ndf))(_)\n",
    "    csize, cndf = isize// 2, ndf\n",
    "    while csize > 5:\n",
    "        assert csize%2==0\n",
    "        in_feat = cndf\n",
    "        out_feat = cndf*2\n",
    "        _ = Conv2D(filters=out_feat, kernel_size=4, strides=2, use_bias=False,\n",
    "                        padding = \"same\",\n",
    "                        kernel_initializer = conv_init,\n",
    "                        name = 'pyramid.{0}-{1}.conv'.format(in_feat, out_feat)             \n",
    "                        ) (_)\n",
    "        if 0: # toggle batchnormalization\n",
    "            _ = BatchNormalization(name = 'pyramid.{0}.batchnorm'.format(out_feat),                                   \n",
    "                                   momentum=0.9, axis=1, epsilon=1.01e-5,\n",
    "                                   gamma_initializer = gamma_init, \n",
    "                                  )(_, training=1)        \n",
    "        _ = LeakyReLU(alpha=0.2, name = 'pyramid.{0}.relu'.format(out_feat))(_)\n",
    "        csize, cndf = (csize+1)//2, cndf*2\n",
    "    _ = Conv2D(filters=1, kernel_size=csize, strides=1, use_bias=False,\n",
    "                        kernel_initializer = conv_init,\n",
    "                        name = 'final.{0}-{1}.conv'.format(cndf, 1)         \n",
    "                        ) (_)\n",
    "    outputs = Flatten()(_)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Üretici Ağ\n",
    "Ayırt edici ağımızı tanımladığımıza göre üretici ağımızı tanımlayalım:\n",
    "\n",
    "![caption](notebook-images/GAN_g.png)\n",
    "\n",
    "Kernel boyutu 4x4 olan ve 3D evrişim modelinin transpose halini içeren üç adet ters evrişim işleminden oluşur. \n",
    "Sonuçta 32x32x3 resimler oluşturur.\n",
    "Burada hiperbolik tanjant aktivasyon fonksiyonu kullanılmıştır. https://keras.io/activations/\n",
    "\n",
    "<img src=\"notebook-images/TanhReal.gif\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCGAN_G(isize, nz, nc, ngf, n_extra_layers=0):\n",
    "    cngf= ngf//2\n",
    "    tisize = isize\n",
    "    while tisize > 5:\n",
    "        cngf = cngf * 2\n",
    "        assert tisize%2==0\n",
    "        tisize = tisize // 2\n",
    "    _ = inputs = Input(shape=(nz,))\n",
    "    _ = Reshape((nz, 1,1))(_)\n",
    "    _ = Conv2DTranspose(filters=cngf, kernel_size=tisize, strides=1, use_bias=False,\n",
    "                           kernel_initializer = conv_init, \n",
    "                           name = 'initial.{0}-{1}.convt'.format(nz, cngf))(_)\n",
    "    _ = BatchNormalization(gamma_initializer = gamma_init, momentum=0.9, axis=1, epsilon=1.01e-5,\n",
    "                               name = 'initial.{0}.batchnorm'.format(cngf))(_, training=1)\n",
    "    _ = Activation(\"relu\", name = 'initial.{0}.relu'.format(cngf))(_)\n",
    "    csize, cndf = tisize, cngf\n",
    "    \n",
    "\n",
    "    while csize < isize//2:\n",
    "        in_feat = cngf\n",
    "        out_feat = cngf//2\n",
    "        _ = Conv2DTranspose(filters=out_feat, kernel_size=4, strides=2, use_bias=False,\n",
    "                        kernel_initializer = conv_init, padding=\"same\",\n",
    "                        name = 'pyramid.{0}-{1}.convt'.format(in_feat, out_feat)             \n",
    "                        ) (_)\n",
    "        _ = BatchNormalization(gamma_initializer = gamma_init, \n",
    "                                   momentum=0.9, axis=1, epsilon=1.01e-5,\n",
    "                                   name = 'pyramid.{0}.batchnorm'.format(out_feat))(_, training=1)\n",
    "        \n",
    "        _ = Activation(\"relu\", name = 'pyramid.{0}.relu'.format(out_feat))(_)\n",
    "        csize, cngf = csize*2, cngf//2\n",
    "    _ = Conv2DTranspose(filters=nc, kernel_size=4, strides=2, use_bias=False,\n",
    "                        kernel_initializer = conv_init, padding=\"same\",\n",
    "                        name = 'final.{0}-{1}.convt'.format(cngf, nc)\n",
    "                        )(_)\n",
    "    outputs = Activation(\"tanh\", name = 'final.{0}.tanh'.format(nc))(_)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrelerimizi tanımlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 3 # number of channels\n",
    "nz = 100\n",
    "ngf = 64 # number of discriminator  features \n",
    "ndf = 64 # number of generator features\n",
    "n_extra_layers = 0\n",
    "Diters = 5 # iteration dimension\n",
    "λ = 10 # wasserstein loss katsayısı\n",
    "\n",
    "imageSize = 32\n",
    "batchSize = 64\n",
    "lrD = 1e-4 # ayırt edici ağ öğrenme katsayısı\n",
    "lrG = 1e-4 # üretici ağ ağ öğrenme katsayısı\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ayırt edici ağ yapımız ve parametre sayıları:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = DCGAN_D(imageSize, nz, nc, ndf, n_extra_layers)\n",
    "netD.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Üretici ağ yapımız ve parametre sayıları:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = DCGAN_G(imageSize, nz, nc, ngf, n_extra_layers)\n",
    "netG.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras'tan optimize edici fonksiyonlarımızı çekelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasserstein Uzaklık fonksiyonumuzu tanımlayalım:\n",
    "Bu uzaklık, normal olmayan sınırların ölçümünü kolaylaştırır...\n",
    "p'nin 1'den büyük ve Pp(M) nin  M içindeki x0 için p. momentindeki µ'nün M'deki olasılık ölçütü olduğunu var sayarsak...\n",
    "<img src=\"notebook-images/mm.png\" />\n",
    "µ ve υ arasındaki p. boyuttaki olasılık ölçütü:  <img src=\"notebook-images/pp.png\" />\n",
    "\n",
    "<img src=\"notebook-images/ww.png\" />\n",
    "\n",
    "<img src=\"notebook-images/w-distance.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD_real_input = Input(shape=(nc, imageSize, imageSize))\n",
    "noisev = Input(shape=(nz,))\n",
    "netD_fake_input = netG(noisev)\n",
    "\n",
    "ϵ_input = K.placeholder(shape=(None,1,1,1))\n",
    "netD_mixed_input = Input(shape=(nc, imageSize, imageSize),\n",
    "    tensor=ϵ_input * netD_real_input + (1-ϵ_input) * netD_fake_input)\n",
    "\n",
    "\n",
    "loss_real = K.mean(netD(netD_real_input))\n",
    "loss_fake = K.mean(netD(netD_fake_input))\n",
    "\n",
    "grad_mixed = K.gradients(netD(netD_mixed_input), [netD_mixed_input])[0]\n",
    "norm_grad_mixed = K.sqrt(K.sum(K.square(grad_mixed), axis=[1,2,3]))\n",
    "grad_penalty = K.mean(K.square(norm_grad_mixed -1))\n",
    "\n",
    "loss = loss_fake - loss_real + λ * grad_penalty\n",
    "\n",
    "\n",
    "training_updates = Adam(lr=lrD, beta_1=0.0, beta_2=0.9).get_updates(netD.trainable_weights,[],loss)\n",
    "netD_train = K.function([netD_real_input, noisev, ϵ_input],\n",
    "                        [loss_real, loss_fake],    \n",
    "                        training_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -loss_fake \n",
    "training_updates = Adam(lr=lrG, beta_1=0.0, beta_2=0.9).get_updates(netG.trainable_weights,[], loss)\n",
    "netG_train = K.function([noisev], [loss], training_updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cifar 10 indirme ve hazırlık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tarfile\n",
    "\n",
    "# Download dataset\n",
    "url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "import os\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "def reporthook(a,b,c):\n",
    "    print(\"\\rdownloading: %5.1f%%\"%(a*b*100.0/c), end=\"\")\n",
    "tar_gz = \"cifar-10-python.tar.gz\"\n",
    "if not os.path.isfile(tar_gz):\n",
    "        print('Downloading data from %s' % url)\n",
    "        urlretrieve(url, tar_gz, reporthook=reporthook)\n",
    "\n",
    "import pickle\n",
    "train_X=[]\n",
    "train_y=[]\n",
    "tar_gz = \"cifar-10-python.tar.gz\"\n",
    "with tarfile.open(tar_gz) as tarf:\n",
    "    for i in range(1, 6):\n",
    "        dataset = \"cifar-10-batches-py/data_batch_%d\"%i\n",
    "        print(\"load\",dataset)\n",
    "        with tarf.extractfile(dataset) as f:\n",
    "            result = pickle.load(f, encoding='latin1')\n",
    "        train_X.extend( result['data'].reshape(-1,3,32,32)/255*2-1)\n",
    "        train_y.extend(result['labels'])\n",
    "    train_X=np.float32(train_X)\n",
    "    train_y=np.int32(train_y)\n",
    "    dataset = \"cifar-10-batches-py/test_batch\"\n",
    "    print(\"load\",dataset)\n",
    "    with tarf.extractfile(dataset) as f:\n",
    "        result = pickle.load(f, encoding='latin1')\n",
    "        test_X=np.float32(result['data'].reshape(-1,3,32,32)/255*2-1)\n",
    "        test_y=np.int32(result['labels'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_X = np.concatenate([train_X[:,:,:,::-1], train_X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar 10 sınıflarını görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def showX(X, rows=1):\n",
    "    assert X.shape[0]%rows == 0\n",
    "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
    "    # N*3072 -> N*3*32*32 -> 32 * 32N * 3\n",
    "    int_X = np.moveaxis(int_X.reshape(-1,3,32,32), 1, 3)\n",
    "    int_X = int_X.reshape(rows, -1, 32, 32,3).swapaxes(1,2).reshape(rows*32,-1, 3)\n",
    "    display(Image.fromarray(int_X))\n",
    "showX(train_X[:20])\n",
    "print(train_y[:20])\n",
    "name_array = np.array(\"airplane car bird cat deer dog frog horse boat truck\".split(' '))\n",
    "print(name_array[train_y[:20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gürültü ekliyoruz..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = np.random.normal(size=(batchSize, nz)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeni resimler üretelim!\n",
    "\n",
    "GAN yapısında dikkat etmemiz gereken nokta; kayıp (loss) fonksiyonlarımız. Elimizde iki adet loss fonksiyonu var, bir tanesi üretici ağın daha iyi resim oluşturmasını sağlıyor diğeri de aynı zamanda ayırt edici ağın üretilen resimlerle verisetinde bulunan resimleri ayırt etmesini sağlıyor.\n",
    "\n",
    "Üretici ve ayırt edici ağlar birlikte çalıştırıldığından, ayırt edici ağ gerçek ve uydurma resimleri ayırt etmede daha iyi hale geliyor, bu sırada üretici ağ ise ağırlık ve bias değerlerini ikna edici resimler oluşturmak üzere ayarlıyor:\n",
    "\n",
    "### İşte sonuçlar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "niter = 100\n",
    "gen_iterations = 0\n",
    "errG = 0\n",
    "targetD = np.float32([2]*batchSize+[-2]*batchSize)[:, None]\n",
    "targetG = np.ones(batchSize, dtype=np.float32)[:, None]\n",
    "for epoch in range(niter):\n",
    "    i = 0\n",
    "    np.random.shuffle(train_X)\n",
    "    batches = train_X.shape[0]//batchSize\n",
    "    while i < batches:\n",
    "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "            _Diters = 100\n",
    "        else:\n",
    "            _Diters = Diters\n",
    "        j = 0\n",
    "        while j < _Diters and i < batches:\n",
    "            j+=1\n",
    "            real_data = train_X[i*batchSize:(i+1)*batchSize]\n",
    "            i+=1\n",
    "            noise = np.random.normal(size=(batchSize, nz))        \n",
    "            ϵ = np.random.uniform(size=(batchSize, 1, 1 ,1))        \n",
    "            errD_real, errD_fake  = netD_train([real_data, noise, ϵ])\n",
    "            errD = errD_real - errD_fake\n",
    "       \n",
    "        if gen_iterations%500==0:\n",
    "            print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "            % (epoch, niter, i, batches, gen_iterations,errD, errG, errD_real, errD_fake), time.time()-t0)\n",
    "            fake = netG.predict(fixed_noise)\n",
    "            showX(fake, 4)\n",
    "        \n",
    "        noise = np.random.normal(size=(batchSize, nz))        \n",
    "        errG, = netG_train([noise])\n",
    "        gen_iterations+=1 \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Çeşitli zorluklar ve Dikkat edilecek noktalar\n",
    "\n",
    "GAN'lar çalıştırılması zor yapılardır, doğru hiperparametre ayarlaması, ağ yapısı, çalıştırılma protokolü gerektirler. Eğer hiperparametreler doğru ayarlanamazsa, ayırt edici ağ üretici ağı yener veya tam tersi olarak üretici ağ kazanır. Bu durumlarda doğru üretim gerçekleşmez.\n",
    "\n",
    "\n",
    "Eğer ayırt edici ağ çok güçlü ayırt ederse, tüm üretilen resimleri her zaman uyduruk olarak sınıflar, bu durumda üretici ağ için türev hesaplanamaz ve dolayısı ile hiç üretim yapılamaz.\n",
    "\n",
    "\n",
    "Bir diğer sorun da **modelin çökmesidir**. Üretici ağ ayırt edici ağ içinde bir zayıflık keşveder ve gürültüyü umursamadan hep aynı tip resimler oluşturur. Bu öğrenme katsayılarının iyi ayarlanması ile çözülebilir.\n",
    "\n",
    "\n",
    "Gan'lar ile ilgili daha fazla ipucu için: [\"GAN hacks\"](https://github.com/soumith/ganhacks) sayfasını ziyaret edebilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diğer Kaynaklar\n",
    "\n",
    "- [Orijinal GAN makalesi](https://arxiv.org/abs/1406.2661) by Ian Goodfellow et al 2014\n",
    "- [En kapsamlı GAN makalesi ](https://arxiv.org/abs/1701.00160) Goodfellow\n",
    "- [Alec Radford, Luke Metz, ve Soumith Chintala DCGAN makaleleri ](https://arxiv.org/abs/1511.06434) DCGAN'ın ilk tanıtım makalesi ve kodu [their DCGAN code on GitHub](https://github.com/Newmu/dcgan_code).\n",
    "- [ Agustinus Kristiadi'den GAN refernasları](https://github.com/wiseodd/generative-models), tensorflow"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
