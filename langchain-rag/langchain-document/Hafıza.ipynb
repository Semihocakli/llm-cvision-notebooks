{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Chatbot gibi uygulamalar yapmak için LLM'leri kullanırıken hafıza önemli bir olaydır ve durumsal olmayan (hafızası olmayan) tokenlerle bu işlemin nasıl yapılacağını göreceğiz.\n",
        "# ConversationBufferMemory (Konuşma Arabellek Hafızası)\n",
        "Önceki konuşmaları da yeni promptlara ekleyip yollar. Fazla token tüketir, hafızası daha güçlüdür."
      ],
      "metadata": {
        "id": "rrLJayXm_mN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import'lar\n",
        "import os\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # lokal .env dosyasından oku\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "qA6eqQgq_sNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.0)\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "qlhCdDD9_suT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Selam, benim adım Harrison.\")\n",
        "conversation.predict(input=\"1+1 ne yapar?\")\n",
        "conversation.predict(input=\"Benim ismim nedir?\")\n",
        "print(memory.buffer)"
      ],
      "metadata": {
        "id": "iFWMIrEI_uSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})\n",
        "memory = ConversationBufferMemory()\n",
        "memory.save_context({\"input\": \"Selam\"},\n",
        "                    {\"output\": \"Naber?\"})\n",
        "print(memory.buffer)"
      ],
      "metadata": {
        "id": "BMMtloIl_v-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})\n",
        "memory.save_context({\"input\": \"Hiç, öyle takılıyorum.\"},\n",
        "                    {\"output\": \"İyii.\"})\n",
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "5eo_PWtd_v5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConversationBufferWindowMemory (Konuşma Arabellek Penceresi Hafızası)\n",
        "Verilen k sayısına kadar önceki konuşmaları yollar böylece belli bir konuşma öncesini unutmaya başlar."
      ],
      "metadata": {
        "id": "hsOKbuVc_1_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "DOOAB58W_0XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "memory.save_context({\"input\": \"Selam\"},\n",
        "                    {\"output\": \"Naber\"})\n",
        "memory.save_context({\"input\": \"Hiç, sadece taklılıyorum.\"},\n",
        "                    {\"output\": \"İyii.\"})\n",
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "Kkp_ATxgACjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.0)\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "IKXSPU7QAEFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Selam, benim adım Harrison.\")\n",
        "conversation.predict(input=\"1+1 ne yapar?\")\n",
        "conversation.predict(input=\"Benim ismim nedir?\")"
      ],
      "metadata": {
        "id": "55d3-RZdAEky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConversationTokenBufferMemory (Konuşma Tokeni Arabellek Hafızası)\n",
        "Konuşma token arabellek hafızası, bellekte son etkileşimlerin bir arabelleğini tutar ve etkileşimlerin temizlenip temizlenmeyeceğini belirlemek için etkileşim sayısı yerine token uzunluğunu kullanır."
      ],
      "metadata": {
        "id": "Xp2VMzU_AGOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tiktoken\n",
        "from langchain.memory import ConversationTokenBufferMemory\n",
        "from langchain.llms import OpenAI\n",
        "llm = ChatOpenAI(temperature=0.0)\n",
        "\n",
        "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
        "memory.save_context({\"input\": \"AI is what?!\"},\n",
        "                    {\"output\": \"Amazing!\"})\n",
        "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
        "                    {\"output\": \"Beautiful!\"})\n",
        "memory.save_context({\"input\": \"Chatbots are what?\"},\n",
        "                    {\"output\": \"Charming!\"})\n",
        "\n",
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "yUcPBUXLAKu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConversationSummaryMemory (Konuşma Özet Arabellek Hafızası)\n",
        "max_token_limit (maksimum token limiti) değeri önceki stringleri verilen değere (bu örnekte 100) karakterli bir özeti şeklinde yolluyor."
      ],
      "metadata": {
        "id": "SdnZe_dbANWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "\n",
        "# uzun bir string oluştur\n",
        "schedule = \"Ürün ekibinizle sabah 8'de bir toplantı var. \\\n",
        "PowerPoint sunumunuzun hazırlanmasına ihtiyacınız olacak. \\\n",
        "09:00-12:00 saatleri arasında LangChain projeniz üzerinde çalışmak için \\\n",
        "zamanınız olacak ve bu, Langchain çok güçlü bir araç olduğu için hızlı bir \\\n",
        "şekilde ilerleyecektir. Öğlen, yapay zekadaki en son gelişmeleri anlamak için \\\n",
        "sizinle buluşmak üzere bir saatten fazla uzaklıktan arabayla gelen bir \\\n",
        "müşteriyle İtalyan restoranında öğle yemeği. \\\n",
        "En son LLM demosunu göstermek için dizüstü bilgisayarınızı getirdiğinizden emin olun.\""
      ],
      "metadata": {
        "id": "6UiD6BoGAOsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
        "memory.save_context({\"input\": \"Selam\"}, {\"output\": \"Naber\"})\n",
        "memory.save_context({\"input\": \"Hiç, öyle takılıyorum\"},\n",
        "                    {\"output\": \"İyii\"})\n",
        "memory.save_context({\"input\": \"Bugün programda neler var?\"},\n",
        "                    {\"output\": f\"{schedule}\"})\n",
        "\n",
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "y79F0T9fAY1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "KSsfRsSeAavi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Göstermek için iyi bir demo ne olurdu?\")\n",
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "QEEagkJuAceQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ekstra Hafıza Tipleri\n",
        "*   Vektör Data Hafızası: Vektör veritabanında metinleri tutar ve en alakalı metin bloklarını çağırır.\n",
        "*   Varlık Hafızası: Bir LLM kullanarak bazı varlıkların detaylarını aklında tutar.\n",
        "\n",
        "Birden fazla hafızayı bir arada da kullanabilirsiniz. Örneğin Konuşma Özet Belleği ile Varlık Hafızası kullanarak bireyleri hatırlamak. Aynı zamanda sohbeti bir geleneksel veritabanında da saklayabilirsiniz."
      ],
      "metadata": {
        "id": "t8aB57acAfhD"
      }
    }
  ]
}